#!/usr/bin/env python3
import torch
from torch import nn
from crop_classification.utils import read_data, TorchDataset, print_metrics
from torch.utils.data import DataLoader
from sklearn.metrics import accuracy_score


class ANN(nn.Module):
    def __init__(self, device):
        self.device = device
        super().__init__()

        self.conv1 = nn.Conv2d(1, 8, (3, 7))
        self.mlp = nn.Sequential(
            nn.Linear(96, 64),
            nn.ReLU(),
            nn.Linear(64, 32),
            nn.ReLU(),
            nn.Linear(32, 7),
        ).to(self.device, dtype=torch.float32)

        self.softmax = nn.Softmax(dim=1).to(self.device, dtype=torch.float32)

    def forward(self, X):
        X = X.unsqueeze(1)
        X = nn.functional.pad(X, (3, 3, 1, 1), "circular")
        X = self.conv1(X).flatten(1, 3)

        return self.softmax(self.mlp(X))


def main():
    torch.cuda.empty_cache()
    torch.autograd.set_detect_anomaly(True)
    torch.multiprocessing.set_start_method("spawn")
    if torch.backends.mps.is_available():
        device = "mps"
    elif torch.cuda.is_available():
        device = "cuda"
    else:
        device = "cpu"
    print(device)

    X_tr, X_te, X_balanced, y_tr, y_te, y_balanced = read_data()

    train_data = TorchDataset(X_tr, y_tr)
    train_dataset, val_dataset = torch.utils.data.random_split(train_data, [0.8, 0.2])
    train_data_loader = DataLoader(
        train_dataset,
        num_workers=0,
        batch_size=64,
        shuffle=True,
        drop_last=True,
    )
    val_data_loader = DataLoader(
        val_dataset,
        batch_size=64,
        num_workers=0,
        shuffle=True,
        drop_last=True,
    )

    model = nn.DataParallel(ANN(device)).to(device, dtype=torch.float32)
    num_params = sum(p.numel() for p in model.parameters())
    print(f"Number of nodes: {num_params}")

    optimizer = torch.optim.SGD(model.parameters(), lr=0.1)
    # scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.8, verbose=True)
    criterion = nn.CrossEntropyLoss().to(device, dtype=torch.float32)

    best_acc = 0.0
    best_model = None
    for epoch in range(100):
        for X_batch, y_batch in train_data_loader:
            X_batch = X_batch.reshape(len(X_batch), 2, 6)
            y_hat = model((X_batch.to(device, dtype=torch.float32)))

            optimizer.zero_grad()

            loss = criterion(
                y_hat,
                nn.functional.one_hot(y_batch.long(), num_classes=7).to(
                    device, dtype=torch.float32
                ),
            )
            loss.backward()
            optimizer.step()

        # scheduler.step()

        val_acc = 0.0
        val_count = 0.0
        val_loss = 0.0
        for X_val, y_val in val_data_loader:
            X_val = X_val.reshape(len(X_val), 2, 6)
            y_val_hat = model((X_val.to(device, dtype=torch.float32)))

            loss = criterion(
                y_val_hat,
                nn.functional.one_hot(y_val.long(), num_classes=7).to(
                    device, dtype=torch.float32
                ),
            )

            y_val_hat = torch.argmax(y_val_hat, dim=1)

            acc = accuracy_score(y_val.cpu().numpy(), y_val_hat.cpu().numpy())

            val_loss += loss * len(X_val)
            val_acc += acc * len(X_val)
            val_count += len(X_val)

        print(
            f"Epoch {epoch}: Validation Loss: {val_loss / val_count} / Accuracy: {val_acc / val_count}"
        )
        if best_acc < val_acc / val_count:
            print("Update model")
            best_acc = val_acc / val_count
            best_model = model

    print("\nTest on imbalanced dataset:")
    X_te = torch.tensor(X_te)
    X_te = X_te.reshape(len(X_te), 2, 6)
    y_pred = best_model((torch.tensor(X_te).to(device, dtype=torch.float32)))
    y_pred = torch.argmax(y_pred, dim=1).cpu().numpy()
    print_metrics(y_pred, y_te)

    print("\nTest on balanced dataset:")
    X_balanced = torch.tensor(X_balanced)
    X_balanced = X_balanced.reshape(len(X_balanced), 2, 6)
    y_pred = best_model((torch.tensor(X_balanced).to(device, dtype=torch.float32)))
    y_pred = torch.argmax(y_pred, dim=1).cpu().numpy()
    print_metrics(y_pred, y_balanced)


if __name__ == "__main__":
    main()
