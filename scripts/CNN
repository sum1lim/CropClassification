#!/usr/bin/env python3
import argparse
import pandas as pd
import numpy as np
import torch
import torch.optim as optim
from torch import nn
from crop_classification.utils import read_data, TorchDataset, accuracy
from torch.utils.data import DataLoader


class CNN(nn.Module):
    def __init__(self, device):
        self.device = device
        super().__init__()

        self.conv1 = nn.Conv2d(1, 2, (3, 3))
        self.conv2 = nn.Conv2d(2, 4, (3, 3))
        self.conv3 = nn.Conv2d(4, 8, (3, 3))
        self.mlp = nn.Sequential(
            nn.Linear(96, 64),
            nn.ReLU(),
            nn.Linear(64, 32),
            nn.ReLU(),
            nn.Linear(32, 7),
        ).to(self.device, dtype=torch.float32)

        self.softmax = nn.Softmax(dim=1).to(self.device, dtype=torch.float32)

    def forward(self, X):
        X = X.unsqueeze(1)
        X = nn.functional.pad(X, (1, 1, 1, 1), "circular")
        X = nn.functional.pad((self.conv1(X)), (1, 1, 1, 1), "circular")
        X = nn.functional.pad((self.conv2(X)), (1, 1, 1, 1), "circular")
        X = self.conv3(X).flatten(1, 3)

        return self.softmax(self.mlp(X))


def main(args):
    torch.cuda.empty_cache()
    torch.autograd.set_detect_anomaly(True)
    torch.multiprocessing.set_start_method("spawn")
    if torch.backends.mps.is_available():
        device = "mps"
    elif torch.cuda.is_available():
        device = "cuda"
    else:
        device = "cpu"
    print(device)

    X_tr, X_te, y_tr, y_te = read_data(balanced_test=args.balanced_test)

    train_data = TorchDataset(X_tr, y_tr)
    train_dataset, val_dataset = torch.utils.data.random_split(train_data, [0.8, 0.2])
    train_data_loader = DataLoader(
        train_dataset,
        num_workers=0,
        batch_size=64,
        shuffle=True,
        drop_last=True,
    )
    val_data_loader = DataLoader(
        val_dataset,
        batch_size=64,
        num_workers=0,
        shuffle=True,
        drop_last=True,
    )

    model = nn.DataParallel(CNN(device)).to(device, dtype=torch.float32)
    optimizer = torch.optim.SGD(model.parameters(), lr=0.1)
    # scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.8, verbose=True)
    criterion = nn.CrossEntropyLoss().to(device, dtype=torch.float32)

    best_acc = 0.0
    best_model = None
    for epoch in range(100):
        for X_batch, y_batch in train_data_loader:
            X_batch = X_batch.reshape(len(X_batch), 2, 6)
            y_hat = model((X_batch.to(device, dtype=torch.float32)))

            optimizer.zero_grad()

            loss = criterion(
                y_hat,
                nn.functional.one_hot(y_batch.long(), num_classes=7).to(
                    device, dtype=torch.float32
                ),
            )
            loss.backward()
            optimizer.step()

        # scheduler.step()

        val_acc = 0.0
        val_count = 0.0
        val_loss = 0.0
        for X_val, y_val in val_data_loader:
            X_val = X_val.reshape(len(X_val), 2, 6)
            y_val_hat = model((X_val.to(device, dtype=torch.float32)))

            loss = criterion(
                y_val_hat,
                nn.functional.one_hot(y_val.long(), num_classes=7).to(
                    device, dtype=torch.float32
                ),
            )

            y_val_hat = torch.argmax(y_val_hat, dim=1)

            acc = accuracy(y_val.to(device, dtype=torch.float32), y_val_hat)

            val_loss += loss * len(X_val)
            val_acc += acc * len(X_val)
            val_count += len(X_val)

        print(
            f"Epoch {epoch}: Validation Loss: {val_loss / val_count} / Accuracy: {val_acc / val_count}"
        )
        if best_acc < val_acc / val_count:
            print("Update model")
            best_acc = val_acc / val_count
            best_model = model

    X_te = torch.tensor(X_te)
    X_te = X_te.reshape(len(X_te), 2, 6)
    y_te_hat = best_model((X_te.to(device, dtype=torch.float32)))
    y_te_hat = torch.argmax(y_te_hat, dim=1)

    acc = accuracy(torch.tensor(y_te).to(device, dtype=torch.float32), y_te_hat)

    print(f"Test accuracy: {acc}")


if __name__ == "__main__":
    parser = argparse.ArgumentParser()

    parser.add_argument(
        "--balanced-test",
        action="store_true",
        help="Test with balanced test dataset",
    )

    args = parser.parse_args()

    main(args)
